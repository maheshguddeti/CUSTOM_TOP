#!/bin/ksh
# /*********************************************************************************************************
# *                                                                                                        *
# * NAME : XXRS_GL_INTERFACE_LOAD.prog                                                                     *
# *                                                                                                        *
# * DESCRIPTION : Script to populate the required field and load the GL_INTERFACE table.                   *
# *                                                                                                        *
# * AUTHOR       : Paddmaja P                                                                              *
# * DATE WRITTEN : 21-Dec-2011                                                                             *
# *                                                                                                        *
# * CHANGE CONTROL :                                                                                       *
# *  Version#     |  Ticket Number     | WHO             |  DATE             |   REMARKS                   *
# *--------------------------------------------------------------------------------------------------------*
# * 1.0.0         |  111122-02448      | Padmaja P       |  12/20/2011       |  Initial Creation           *
# **********************************************************************************************************/
# $Header: XXRS_GL_INTERFACE_LOAD.prog 1.0.0 21/12/2010 10:00:00 AM Padmaja $
file_exists()
{
  for file in ${1}; do
    if [ -e $file ]; then
      return
    fi
  done
#
  echo "---------------------------------------------------------------------------------"
  echo "No file is found to copy."
  echo "---------------------------------------------------------------------------------"
  echo " "
#
  echo " "
  echo "Submitting GL Interface program."
  echo " "
#
sqlplus -s ${p_apps_usrn_pwd} << EOF
SET SERVEROUTPUT ON SIZE 1000000
SET Verify ON;
WHENEVER SQLERROR EXIT 8
VARIABLE RET_STATUS NUMBER
declare
p_user_id NUMBER := ${p_user_id};
p_resp_id NUMBER := ${p_resp_id};
p_conc_req_id NUMBER := ${p_conc_request_id};
p_error_code NUMBER;
begin
XXRS_GL_INTERFACE_PKG.submit_journal_import(0,p_conc_req_id,p_user_id,p_resp_id,:RET_STATUS);
end;
/
exit :RET_STATUS;

EOF
#     
  l_imp_con_req=$?
  wait
#
#
  case ${l_imp_con_req} in
#
     2) echo "***Could not submit the concurrent request. Please submit the journal import manually.***"
        exit 1;;
#
     8) echo "***Internal error while submitting the journal import. Please submit the journal import manually.***"
        exit 1;;
#
     0) echo "SUCCESSFULLY Submitted journal imports"
        exit 0;;
#
     1) echo "PARTIALY Submitted journal imports. There are other set of books journal entries still not imported."
        echo "Please other journal imports manually."
        exit 0;;
#
     *) echo "***Unexpected error in submitting the journal import. Please submit the journal import manually.***"
        exit 1;;
#
     esac
  exit 0 
}
#
echo "-----------------------------------------------------------------------"
echo "Start of GL Interface Load Script."
echo "Time: "`date +%Y%m%d%H%M%S`
echo "-----------------------------------------------------------------------"
echo " "
#
# ----------------------------------------------------------------------------
# Assumption: The file is formatted to according to the specification document
# Need to initialize parameters for the shell script
# ----------------------------------------------------------------------------
#
p_apps_usrn_pwd=$1
p_user_id=$2
p_user_name=$3
p_conc_request_id=$4
p_resp_id=$5
p_file_name=$6
#p_country=$7
l_error_flag=F
l_stage_location=${XXRS_TOP}/data/gl
l_archive_location=${XXRS_TOP}/archive/gl
l_ctl_file=XXRS_GL_INTERFACE_LOAD
l_env=`echo $TWO_TASK | awk '{print substr($0,0,3)}'`
datetime=`date +%Y%m%d%H%M%S`
#
echo "-----------------------------------------------------------------------"
echo "Parameters being passed from Oracle Concurrent Job:"
echo " "
echo "User Id            =  ${p_user_id}"
echo "User Name          =  ${p_user_name}"
echo "Request ID         =  ${p_conc_request_id}"
echo "Date Time          =  ${datetime}"
echo "File name pattern  =  ${p_file_name}"
echo "-----------------------------------------------------------------------"
echo " "
#
# ---------------------------------------------------------------------------
# Get the file from the SFTP site and place the file in data folder. Once
# file is placed in the data folder then iterate through the file and remove
# it from the SFTP site and decrypt the file for loading the file into the 
# staging table.
# ---------------------------------------------------------------------------
#
if [ $l_env = "PRD" ]; then
#
  cd ${l_stage_location}
#
sftp workdayprd@ftp1.ord1.corp.rackspace.com<< EOF_FTP
cd oracle_inbound
get ${p_file_name}*.gpg
EOF_FTP
#
else
#
  cd ${l_stage_location}
#
sftp workdaydev@ftp1.ord1.corp.rackspace.com<< EOF_FTP
cd oracle_inbound
get ${p_file_name}*.gpg
EOF_FTP
#
fi
#
# ---------------------------------------------------------------------------
# Check For Successful File Transfer from Rackspace SFTP Server to
# Rackspace App Server.If Success then remove the file from sftp site.
# ---------------------------------------------------------------------------
#
if (($? != 0))     # Examine error status
then
  echo " "
  echo "Error while fetching file(s) from Rackspace SFTP server into App Server"
  echo "---------------------------------------------------------------------------------"
  exit 1
fi
#
file_exists ${p_file_name}*.gpg
#
echo " "
echo "One or more files exist to be processed. STARTING processing.."
echo " "
#
cd ${l_stage_location}
#
for file in ${p_file_name}*.gpg; do
  if [ -e ${file} ]; then
#
    echo " "
    echo "-----------------------------------------------------------------------"
    echo "Processing import file ${file}.."
    echo " "
#
# ---------------------------------------------------------------------------
# Remove the file from the SFTP server once the we have confirmed the file 
# exist in the application server. If there is no error then continue 
# processing the file and extract the filename without the extension .gpg
# ---------------------------------------------------------------------------
#
    if [ $l_env = "PRD" ]; then
#
sftp workdayprd@ftp1.ord1.corp.rackspace.com<< EOF_FTP
cd oracle_inbound
rm ${file}
EOF_FTP
#
    else
#
sftp workdaydev@ftp1.ord1.corp.rackspace.com<< EOF_FTP
cd oracle_inbound
rm ${file}
EOF_FTP
#
    fi
#
    if (($? != 0)) then
      echo "ERROR!!! while deleting file ${file} from Rackspace SFTP Server"
      echo " "
    else
      echo "REMOVED file ${file} from the Rackspace SFTP server."
      echo " "
    fi
#
# -----------------------------------------------------------------------------------------
# Decrypt the file into an .csv file for processing
# -----------------------------------------------------------------------------------------
#
    echo "Decrypting response file "${file}
#
    l_file_name=`echo ${file} | sed s/.gpg\$//`
#
    echo "${l_file_name}.csv"
    gpg -d ${file} > ${l_file_name}.csv
#
    if [ "$?" = "0" ]; then
#
# remove exiting xml response file  
#
      rm -f ${file}
      echo " [ DONE ]"
    else
      echo " [ FAILED ]"
      exit 1
    fi
#
# ---------------------------------------------------------------------------
# Check to see if this a normal load or a reverse load.  If so then check
# to see if the file has already been processed by checking the archive 
# directory to see if the file exists in the directory. If we already have
# run the unload then delete the previous file so that we keep the processed
# data check in synch.
# ---------------------------------------------------------------------------
#
    echo "Checking for already processed files                                   "
    echo " "
#
    archive_file_count=`ls  ${l_archive_location}/${l_file_name}_*_C.dat.gpg.gz | wc -l`
#
    if [ ${archive_file_count} -ge 1 ]; then
# 
      echo " "
      echo "-----------------------------------------------------------------------"
      echo "Error :: File already processed, found in archive directory."
      echo " "
      echo "SKIPPING file ${l_file_name}.csv execution.. "
      continue
#
    else
#
      echo " "
      echo "File was never processed. Continue loading the file. "
      echo " "
#
    fi
#
# ---------------------------------------------------------------------------
# Convert the file to Unix format
# ---------------------------------------------------------------------------
#
    cp -p ${l_stage_location}/${l_file_name}.csv ${l_stage_location}/${l_file_name}.csv.dos
    wait
    dos2unix -n ${l_stage_location}/${l_file_name}.csv.dos ${l_stage_location}/${l_file_name}.csv
#
    if [ -f ${l_stage_location}/${l_file_name}.csv.dos ]; then
       rm -f ${l_stage_location}/${l_file_name}.csv.dos
    fi
#
# ---------------------------------------------------------------------------
# Get the next sequence for the group id so that the records could be 
# assigned to process 
# ---------------------------------------------------------------------------
#
l_group_id=`sqlplus -silent ${p_apps_usrn_pwd} <<EOF
SET HEAD OFF
SELECT gl_interface_control_s.nextval
  FROM dual;
EXIT;
EOF`
#
    l_group_id=`echo ${l_group_id}|tr -s "" " "`
#
# ---------------------------------------------------------------------------
# Append the concurrent request id to allow a rollback to occur 
# if there are any error records. Renaming the file back to *.csv
# ---------------------------------------------------------------------------
#
    echo "-----------------------------------------------------------------------"
    echo "Adding concurrent request id to each data record for rolling back."
    echo "-----------------------------------------------------------------------"
    echo " "
#
    cat ${l_stage_location}/${l_file_name}.csv | sed 's/$'"/`echo ','${l_group_id}','${p_conc_request_id}','${p_user_id}','${l_file_name}`/" > ${l_stage_location}/${l_file_name}.dat
#
    rm -f ${l_stage_location}/${l_file_name}.csv
    cp -p ${l_stage_location}/${l_file_name}.dat ${l_stage_location}/${l_file_name}.csv
    rm -f ${l_stage_location}/${l_file_name}.dat
#
# ---------------------------------------------------------------------------
# Clean up the log directory that houses the log, bad, and discard files 
# that SQL Loader produces.
# ---------------------------------------------------------------------------
#
    echo "-----------------------------------------------------------------------"
    echo "Remove old .log, .bad, and .dsc SQL Loader files from directory."
    echo "-----------------------------------------------------------------------"
    echo " "
#
    if [ -f ${XXRS_TOP}/log/${l_file_name}.log ]; then
      rm ${XXRS_TOP}/log/${l_file_name}.log
    fi
#
    if [ -f ${XXRS_TOP}/log/${l_file_name}.bad ]; then
      rm ${XXRS_TOP}/log/${l_file_name}.bad
    fi
#
    if [ -f ${XXRS_TOP}/log/${l_file_name}.dsc ]; then
      rm ${XXRS_TOP}/log/${l_file_name}.dsc
    fi
#
# ----------------------------------------------------------------------------
# Call the SQL Loader to load the data into the invoice worksheet table
# ----------------------------------------------------------------------------
#
    echo "-----------------------------------------------------------------------"
    echo "Running SQL Loader process."
    echo "-----------------------------------------------------------------------"
    echo " " 
#
    sqlldr userid=${p_apps_usrn_pwd} data=${l_stage_location}/${l_file_name}.csv \
                                  control=${XXRS_TOP}/bin/${l_ctl_file}.ctl \
                                      log=${XXRS_TOP}/log/${l_file_name}.log \
                                      bad=${XXRS_TOP}/log/${l_file_name}.bad \
                                  discard=${XXRS_TOP}/log/${l_file_name}.dsc \
                                   errors=0 \
                               discardmax=1
    return_status=$?
    wait
#
# ---------------------------------------------------------------------------
# Check the return status of the SQL Loader command.  If there are any 
# errors, warnings, fatal, or unknown errors, then rollback all the changes 
# in the Unload script and remove the usage data file. If all the rows in 
# the datafile are loaded successfully, then move the processed file to the 
# archive directory for auditing purposes both in the network drive and on 
# the Oracle side.  If the process opts is validate only then we need to
# unload the data from the staging table.  This process will be launched
# from the audit script automatically.
# ---------------------------------------------------------------------------
#
    echo " " 
    echo "Checking the SQL Loader status."
    echo " " 
#
    case ${return_status} in
       0) echo "SQL*Loader execution SUCCESSFUL.  Archiving data file loaded." 
          echo " "
          echo | cat ${XXRS_TOP}/log/${l_file_name}.log
          echo " " 
          loader_status=SUCCESS;;      
#
       1) echo "SQL*Loader execution exited with FAILURE, see logfile."
          echo " " 
          echo | cat ${XXRS_TOP}/log/${l_file_name}.log
          echo " "
          echo "-----------------------------------------------------------------------"
          echo "Bad Record is : "
          echo | cat ${XXRS_TOP}/log/${l_file_name}.bad
          echo " "
          echo "-----------------------------------------------------------------------" 
          l_error_flag=T
          loader_status=FAIL;;
#
       2) echo "SQL*Loader execution exited with WARNING, see logfile."
          echo " " 
          echo | cat ${XXRS_TOP}/log/${l_file_name}.log
          echo " "
          echo "-----------------------------------------------------------------------"
          echo "Bad Record is : "
          echo | cat ${XXRS_TOP}/log/${l_file_name}.bad
          echo " "
          echo "-----------------------------------------------------------------------"
          l_error_flag=T
          loader_status=WARNING;;
#
       3) echo "SQL*Loader execution encountered a FATAL ERROR."
          echo " " 
          echo | cat ${XXRS_TOP}/log/${l_file_name}.log
          echo " "
          l_error_flag=T
          loader_status=FATAL;;
#
       *) echo "UNKNOWN return code."
          echo " " 
          echo | cat ${XXRS_TOP}/log/${l_file_name}.log
          echo " "
          echo "-----------------------------------------------------------------------"
          echo "Bad Record is : "
          echo | cat ${XXRS_TOP}/log/${l_file_name}.bad
          echo " "
          echo "-----------------------------------------------------------------------"
          l_error_flag=T
          loader_status=UNKNOWN;;
#
    esac
#
# -----------------------------------------------------------------------------
# If the loader return status is sucessful then submit the GL Interface program
# and archive the data file
# -----------------------------------------------------------------------------
#
    if [ ${loader_status} = SUCCESS ]; then
#
      echo "-----------------------------------------------------------------------"
      echo "Calling XXRS_GL_INTERFACE_PKG.VALIDATE_LOAD program                    "
      echo "-----------------------------------------------------------------------"
sqlplus -s ${p_apps_usrn_pwd} << EOF
SET SERVEROUTPUT ON SIZE 1000000
SET Verify ON;
WHENEVER SQLERROR EXIT 8
VARIABLE RET_STATUS NUMBER
declare
p_group_id NUMBER := ${l_group_id};
p_conc_req_id NUMBER := ${p_conc_request_id};
p_error_code NUMBER;
begin
XXRS_GL_INTERFACE_PKG.validate_load(p_group_id,p_conc_req_id,:RET_STATUS);
end;
/
exit :RET_STATUS;

EOF
#
      return_status=$?
      wait
#
      echo " "
      echo "-----------------------------------------------------------------------"
      echo "End of XXRS_GL_INTERFACE_PKG.VALIDATE_LOAD program "
      echo "-----------------------------------------------------------------------"
      echo " "
#
      if [ ${return_status} -ne 0 ]; then
#
        echo "-----------------------------------------------------------------------"
        echo "ERROR! GL Interface validation failed!! Rolling back the changes..     "
        echo "-----------------------------------------------------------------------"
sqlplus -s ${p_apps_usrn_pwd} << EOF
SET SERVEROUTPUT ON SIZE 1000000
SET Verify ON;
WHENEVER SQLERROR EXIT 8
VARIABLE ROLL_STATUS NUMBER
declare
p_group_id NUMBER := ${l_group_id};
p_conc_req_id NUMBER := ${p_conc_request_id};
p_error_code NUMBER;
begin
XXRS_GL_INTERFACE_PKG.remove_data(p_group_id,p_conc_req_id,:ROLL_STATUS);
end;
/
exit :ROLL_STATUS;

EOF
#
        rollback_status=$?
        wait
#
        if [ ${rollback_status} -eq 0 ]; then
#
          echo " "
          echo "Rollback completed. Please correct the issue and reload data!         "
          echo " "
          l_error_flag=T
#
        else
#
          echo " "
          echo "Rolling back failed!! Please purge the data from the staging table.   "
          echo " "
          l_error_flag=T
#
        fi
#
        echo " "
        echo "Archiving data file. Marking archive file as failed "
        echo " "
#
        mv -f ${l_stage_location}/${l_file_name}.csv \
            ${l_archive_location}/${l_file_name}'_'${p_conc_request_id}'_'${datetime}_F.dat
        gpg -e --default-recipient 'OracleDBA' ${l_archive_location}/${l_file_name}'_'${p_conc_request_id}'_'${datetime}_F.dat
        gzip ${l_archive_location}/${l_file_name}'_'${p_conc_request_id}'_'${datetime}_F.dat.gpg
        rm -f ${l_archive_location}/${l_file_name}'_'${p_conc_request_id}'_'${datetime}_F.dat
        wait
#
        find ${l_archive_location}/ -ctime +90 -name *gpg*gz -exec rm {} \;
#
        echo "SKIPPING file ${l_file_name}.csv execution.. "
        continue
      else
#
        echo " "
        echo "Submitting GL Interface program."
        echo " "
#
sqlplus -s ${p_apps_usrn_pwd} << EOF
SET SERVEROUTPUT ON SIZE 1000000
SET Verify ON;
WHENEVER SQLERROR EXIT 8
VARIABLE RET_STATUS NUMBER
declare
p_user_id NUMBER := ${p_user_id};
p_resp_id NUMBER := ${p_resp_id};
p_group_id NUMBER := ${l_group_id};
p_conc_req_id NUMBER := ${p_conc_request_id};
p_error_code NUMBER;
begin
XXRS_GL_INTERFACE_PKG.submit_journal_import(p_group_id,p_conc_req_id,p_user_id,p_resp_id,:RET_STATUS);
end;
/
exit :RET_STATUS;

EOF
#     
        l_imp_con_req=$?
        wait
#
#
        case ${l_imp_con_req} in
#
          2) echo "***Could not submit the concurrent request. Please submit the journal import manually.***"
             l_error_flag=T
             submit_status=ERROR;;
#
          8) echo "***Internal error while submitting the journal import. Please submit the journal import manually.***"
             l_error_flag=T
             submit_status=ERROR;;
#
          0) echo "SUCCESSFULLY Submitted journal imports"
             submit_status=SUCCESS;;
#
          1) echo "PARTIALY Submitted journal imports. There are other set of books journal entries still not imported."
             echo "Please other journal imports manually."
             submit_status=SUCCESS;;
#
          *) echo "***Unexpected error in submitting the journal import. Please submit the journal import manually.***"
             l_error_flag=T
             submit_status=ERROR;;
#
        esac
#
        echo " "
        echo "Archiving data file. Marking archive file as completed "
        echo " "
#
        mv -f ${l_stage_location}/${l_file_name}.csv \
            ${l_archive_location}/${l_file_name}'_'${p_conc_request_id}'_'${datetime}_C.dat
        gpg -e --default-recipient 'OracleDBA' ${l_archive_location}/${l_file_name}'_'${p_conc_request_id}'_'${datetime}_C.dat
        gzip ${l_archive_location}/${l_file_name}'_'${p_conc_request_id}'_'${datetime}_C.dat.gpg
        rm -f ${l_archive_location}/${l_file_name}'_'${p_conc_request_id}'_'${datetime}_C.dat
        wait
#
        find ${l_archive_location}/ -ctime +90 -name *gpg*gz -exec rm {} \;
#
        echo "-----------------------------------------------------------------------"
        echo "GL Interface Load execution is SUCCESSFUL for file ${l_file_name}.csv  "
        echo "-----------------------------------------------------------------------"
        echo " "
#
        if [ ${submit_status} = "ERROR" ]; then
          echo " "
          echo "SKIPPING file ${l_file_name}.csv execution.. "
          continue
        fi
#
      fi
#
    else
#
# --------------------------------------------------------------------------------
# Need to remove if there are any residual data through the SQL Loader program.
# Finally, the file will be archived as a failure process.
# --------------------------------------------------------------------------------
# 
      echo "-----------------------------------------------------------------------"
      echo "ERROR! GL Interface Load failed!! Rolling back the changes            "
      echo "-----------------------------------------------------------------------"
      echo " "
#
sqlplus -s ${p_apps_usrn_pwd} << EOF
SET SERVEROUTPUT ON SIZE 1000000
SET Verify ON;
WHENEVER SQLERROR EXIT 8
VARIABLE RET_STATUS NUMBER
declare
p_group_id NUMBER := ${l_group_id};
p_conc_req_id NUMBER := ${p_conc_request_id};
p_error_code NUMBER;
begin
XXRS_GL_INTERFACE_PKG.remove_data(p_group_id,p_conc_req_id,:RET_STATUS);
end;
/
exit :RET_STATUS;

EOF
#     
      rollback_status=$?
      wait
#
      if [ ${rollback_status} -eq 0 ]; then
#
        echo " "
        echo "Rollback completed. Please correct the issue and reload data!         "
        echo " "
        l_error_flag=T
#
      else
#
        echo " "
        echo "Rolling back FAILED!! Please purge the data from the staging table.   "
        echo " "
        l_error_flag=T
#
      fi
#
      echo " "
      echo "Archiving data file. Marking archive file as failed "
      echo " "
#
      mv -f ${l_stage_location}/${l_file_name}.csv \
           ${l_archive_location}/${l_file_name}'_'${p_conc_request_id}'_'${datetime}_F.dat
      gpg -e --default-recipient 'OracleDBA' ${l_archive_location}/${l_file_name}'_'${p_conc_request_id}'_'${datetime}_F.dat
      gzip ${l_archive_location}/${l_file_name}'_'${p_conc_request_id}'_'${datetime}_F.dat.gpg
      rm -f ${l_archive_location}/${l_file_name}'_'${p_conc_request_id}'_'${datetime}_F.dat
      wait
#
      find ${l_archive_location}/ -ctime +90 -name *gpg*gz -exec rm {} \;
#
      echo "SKIPPING file ${l_file_name}.csv execution.. "
      continue
    fi
#
  fi
#
done
#
if [ ${l_error_flag} = "T" ]; then
   echo " "
   echo "Some or all of the file import FAILED to load successfully. Please review this log. "
   exit 1
fi
#
exit